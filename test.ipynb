{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import streamlit as st\n",
    "import re\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# from keyword import iskeyword\n",
    "# Function to create a MySQL connection\n",
    "    \n",
    "def create_connection(database, user, password, host='localhost'):    \n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            database=database\n",
    "        )\n",
    "        \n",
    "        if connection.is_connected():\n",
    "            print(f\"The name {database} is already in use !\")\n",
    "            return \"Database name already in use !\"\n",
    "    except Error as e:\n",
    "        # Check if the error is related to the database not existing\n",
    "        if \"Unknown database\" in str(e):\n",
    "            try:\n",
    "                # If the database doesn't exist, create a new one\n",
    "                connection = mysql.connector.connect(\n",
    "                    host=host,\n",
    "                    user=user,\n",
    "                    password=password\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "                cursor.execute(f\"CREATE DATABASE {database}\")\n",
    "                print(f\"Database '{database}' created successfully.\")\n",
    "                connection.close()\n",
    "\n",
    "                # Now, attempt to connect to the newly created database\n",
    "                connection = mysql.connector.connect(\n",
    "                    host=host,\n",
    "                    user=user,\n",
    "                    password=password,\n",
    "                    database=database\n",
    "                )\n",
    "\n",
    "                if connection.is_connected():\n",
    "                    print(f\"Connected to the database: {database}\")\n",
    "                   \n",
    "                    return connection\n",
    "\n",
    "            except Error as e:\n",
    "                print(f\"Error creating or connecting to the database: {e}\")\n",
    "                return None\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        \n",
    "# def infer_data_type(series):\n",
    "#     # Infer the data type of the column based on the first non-null value\n",
    "#     if pd.api.types.is_numeric_dtype(series):\n",
    "#         data_type = 'NUMERIC'   \n",
    "#     elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "#         data_type = 'DATETIME'\n",
    "#     elif pd.api.types.is_string_dtype(series):\n",
    "#         # Check for string (TEXT or VARCHAR based on length)\n",
    "#         # max_length = series.str.len().max()\n",
    "#         # data_type = f\"VARCHAR({min(max_length, 255)})\"\n",
    "#         data_type = \"TEXT\"\n",
    "\n",
    "#     elif pd.api.types.is_bool_dtype(series):\n",
    "#         data_type = 'BOOLEAN'   \n",
    "#     else:\n",
    "#         # Default to TEXT if the data type is not recognized\n",
    "#         data_type = 'TEXT'\n",
    "        \n",
    "#     # print(f\"Column data type: {data_type}\")\n",
    "#     return data_type\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import re\n",
    "\n",
    "def infer_data_type_auto(series, majority_threshold=0.9):\n",
    "    # Function to check if a string represents a numeric value\n",
    "    def is_numeric(value):\n",
    "        return bool(re.match(r'^\\s*-?\\d+(\\.\\d+)?\\s*$', str(value)))\n",
    "\n",
    "    # Function to check if a string represents a date-only value\n",
    "    def is_date(value):\n",
    "        return bool(re.match(r'^(\\d{4}-\\d{2}-\\d{2}|\\d{2}-\\d{2}-\\d{4})$', str(value)))\n",
    "\n",
    "    # Function to check if a string represents a datetime value\n",
    "    def is_datetime(value):\n",
    "        return bool(re.match(r'^\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}$', str(value)))\n",
    "\n",
    "    # Function to check if a string represents a boolean value\n",
    "    def is_boolean(value):\n",
    "        return str(value).lower() in ['true', 'false']\n",
    "\n",
    "    # Count the number of values for each data type\n",
    "    numeric_count = series.apply(is_numeric)\n",
    "    date_count = series.apply(is_date)\n",
    "    datetime_count = series.apply(is_datetime)\n",
    "    boolean_count = series.apply(is_boolean)\n",
    "    text_count = ~(numeric_count | date_count | datetime_count | boolean_count)\n",
    "\n",
    "    total_count = len(series)\n",
    "\n",
    "    # Calculate percentages of values for each data type\n",
    "    numeric_percentage = numeric_count.sum() / total_count\n",
    "    date_percentage = date_count.sum() / total_count\n",
    "    datetime_percentage = datetime_count.sum() / total_count\n",
    "    boolean_percentage = boolean_count.sum() / total_count\n",
    "    text_percentage = text_count.sum() / total_count\n",
    "\n",
    "    # Create a dictionary of data type percentages\n",
    "    type_percentages = {\n",
    "        'NUMERIC': numeric_percentage,\n",
    "        'DATE': date_percentage,\n",
    "        'DATETIME': datetime_percentage,\n",
    "        'TEXT': text_percentage,\n",
    "        'BOOLEAN': boolean_percentage\n",
    "    }\n",
    "\n",
    "    print(\"type_percentages:\", type_percentages)\n",
    "\n",
    "    # Infer the data type based on the majority percentage\n",
    "    inferred_type = max(type_percentages, key=type_percentages.get)\n",
    "\n",
    "    # Check if the majority percentage exceeds the threshold\n",
    "    if type_percentages[inferred_type] >= majority_threshold:\n",
    "        data_type = inferred_type\n",
    "    else:\n",
    "        # Default to TEXT if the majority data type is not recognized\n",
    "        data_type = 'TEXT'\n",
    "\n",
    "    print(\"returned data type:\", data_type)\n",
    "\n",
    "    return data_type\n",
    "\n",
    "\n",
    "def infer_data_type(series):\n",
    "    # Infer the data type of the column based on the first non-null value\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        data_type = 'NUMERIC'   \n",
    "    elif pd.api.types.is_float_dtype(series):\n",
    "            data_type = 'FLOAT'\n",
    "    elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "        data_type = 'DATETIME'\n",
    "    elif pd.api.types.is_string_dtype(series):\n",
    "        # Check for string (TEXT or VARCHAR based on length)\n",
    "        # max_length = series.str.len().max()\n",
    "        # data_type = f\"VARCHAR({min(max_length, 255)})\"\n",
    "        data_type = \"TEXT\"\n",
    "\n",
    "    elif pd.api.types.is_bool_dtype(series):\n",
    "        data_type = 'BOOLEAN'   \n",
    "    else:\n",
    "        # Default to TEXT if the data type is not recognized\n",
    "        data_type = 'TEXT'\n",
    "        \n",
    "    # print(f\"Column data type: {data_type}\")\n",
    "    return data_type\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sql_keywords = [\n",
    "    'DATABASE','SELECT', 'FROM', 'WHERE', 'ORDER BY', 'GROUP BY', 'JOIN',\n",
    "    'UNION', 'INSERT', 'UPDATE',\n",
    "    'DELETE', 'CREATE', 'ALTER', 'DROP', 'TABLE', 'VIEW', 'INDEX', 'PRIMARY',\n",
    "    'FOREIGN', 'KEY', 'CONSTRAINT', 'AND', 'OR', 'NOT', 'IN', 'LIKE', 'BETWEEN',\n",
    "    'IS', 'NULL', 'ASC', 'DESC', 'AS', 'DISTINCT', 'ON', 'HAVING', 'LIMIT',\n",
    "    'OFFSET', 'COUNT', 'SUM', 'AVG', 'MIN', 'MAX', 'UPPER', 'LOWER', 'CASE',\n",
    "    'WHEN', 'THEN', 'ELSE', 'END', 'JOIN', 'INNER', 'OUTER', 'LEFT', 'RIGHT',\n",
    "    'FULL', 'ALL', 'ANY', 'EXISTS', 'CASE', 'WHEN', 'THEN', 'ELSE', 'END'\n",
    "]\n",
    "\n",
    "def is_sql_keyword(word):\n",
    "    return word.upper() in sql_keywords\n",
    "\n",
    "def clean_column_name(col):\n",
    "    # Remove leading and trailing spaces\n",
    "    cleaned_col = col.strip()\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    cleaned_col = cleaned_col.replace(\" \", \"_\")\n",
    "    \n",
    "    # Replace special characters with underscores\n",
    "    cleaned_col = re.sub(r'[^a-zA-Z0-9_]', '', cleaned_col)\n",
    "    \n",
    "    # Check if the cleaned column name is an SQL keyword\n",
    "    if is_sql_keyword(col):\n",
    "        cleaned_col = f\"{col}_\"\n",
    "    \n",
    "    # if iskeyword(cleaned_col.upper()):\n",
    "    #     cleaned_col = f\"{cleaned_col}_\"\n",
    "    \n",
    "    return cleaned_col\n",
    "\n",
    "# Function to create tables and insert data\n",
    "def excel_to_mysql(excel_file, database,cleaning_strategy):\n",
    "    # user = 'root'\n",
    "    # password = 'BJe11cybiR7WpXgfmQJs'\n",
    "    # host = '70.98.204.225'\n",
    "    \n",
    "    # user = 'root'\n",
    "    # password = 'atm8019atM@'\n",
    "    # host = 'localhost'\n",
    "    user = 'root'\n",
    "    password = 'BJe11cybiR7WpXgfmQJs'\n",
    "    host = '70.98.204.225'\n",
    "    schema = {}\n",
    "    # Read Excel file into a dictionary of DataFrames\n",
    "    xls_data = pd.read_excel(excel_file, sheet_name=None)\n",
    "\n",
    "    # Create a MySQL connection\n",
    "    connection = create_connection(database, user, password, host)\n",
    "    if connection is None :\n",
    "        return\n",
    "\n",
    "    elif connection == \"Database name already in use !\":\n",
    "        return \"Database name already in use !\"\n",
    "    \n",
    "    else:   \n",
    "        try:\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Iterate through sheets and create tables\n",
    "            for sheet_name, sheet_data in xls_data.items():\n",
    "                \n",
    "                # Use sheet name as table name (you may need to sanitize the sheet names)\n",
    "                table_name = sheet_name.lower().replace(\" \", \"_\")\n",
    "                print(f\"Creating table '{table_name}'\")\n",
    "\n",
    "                cleaned_column_names = [clean_column_name(col) for col in sheet_data.columns]\n",
    "                print(\"cleaned_column_names RE:\", cleaned_column_names)\n",
    "                if cleaning_strategy=='manual':\n",
    "                    column_types = {col: infer_data_type(sheet_data[col]) for col in sheet_data.columns}\n",
    "                    print(\"\\n\\nColumn Types:\", column_types)\n",
    "                elif cleaning_strategy == 'auto' :\n",
    "                    column_types = {col: infer_data_type_auto(sheet_data[col]) for col in sheet_data.columns}\n",
    "                    print(\"\\n\\nColumn Types:\", column_types)\n",
    "                \n",
    "                # Create the CREATE TABLE query\n",
    "                create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} ({', '.join([f'`{col}` {col_type}' for col, col_type in zip(cleaned_column_names, column_types.values())])})\"\n",
    "                print(\"create_table_query: \", create_table_query)\n",
    "                cursor.execute(create_table_query)\n",
    "                print(f\"Table '{table_name}' created\")\n",
    "\n",
    "                # Iterate through sheets again and insert data into tables\n",
    "                if cleaning_strategy == 'auto':\n",
    "                    # for sheet_name, sheet_data in xls_data.items():\n",
    "                        # table_name = sheet_name.lower().replace(\" \", \"_\")\n",
    "\n",
    "                    for _, row in sheet_data.iterrows():\n",
    "                        for col, data_type in column_types.items():\n",
    "                            if data_type == 'NUMERIC':\n",
    "                                row[col] = pd.to_numeric(row[col], errors='coerce')\n",
    "                            elif data_type == 'DATE':\n",
    "                                row[col] = pd.to_datetime(row[col], errors='coerce').date() if pd.notna(row[col]) else None\n",
    "                            elif data_type == 'DATETIME':\n",
    "                                row[col] = pd.to_datetime(row[col], errors='coerce')    \n",
    "                            elif data_type == 'TEXT':\n",
    "                                # You may add additional text handling logic if needed\n",
    "                                pass\n",
    "                            elif data_type == 'BOOLEAN':\n",
    "                                row[col] = str(row[col]).lower() in ['true', '1', 'yes','false']\n",
    "\n",
    "                        # Convert NaN values to None\n",
    "                        row = row.where(pd.notna(row), None)\n",
    "\n",
    "                        insert_query = f\"INSERT INTO {table_name} VALUES ({', '.join(['%s']*len(row))})\"\n",
    "                        \n",
    "                        # logging.debug(f\"Insert query: \", insert_query, tuple(row))\n",
    "                        print(f\"Insert query: \", insert_query, tuple(row))\n",
    "                        \n",
    "                        cursor.execute(insert_query, tuple(row))\n",
    "                        \n",
    "                    connection.commit()\n",
    "                    # logging.debug(f\"Data inserted into '{table_name}' table\")\n",
    "                    print(f\"Data inserted into '{table_name}' table\")\n",
    "\n",
    "                elif cleaning_strategy == 'manual':\n",
    "                    # for sheet_name, sheet_data in xls_data.items():\n",
    "                        for _, row in sheet_data.iterrows():\n",
    "                            # print('table name: ',table_name,'row:',row)1  \n",
    "                            \n",
    "                            # Replace 'NA' or other non-numeric values with a default value, replaces empty cells with NAN, handles data type issues\n",
    "                            # This is an anonymous (lambda) function that takes an argument x (each element of the Series) and returns 0 if the element is either NaN (pd.isna(x)) or an empty string (x == ''), and returns the original value x otherwise.\n",
    "                            # row = row.apply(lambda x: 0 if pd.isna(x) or x == '' else x)\n",
    "                            \n",
    "                            row = row.apply(lambda x: None if pd.isna(x) or x == '' else x)\n",
    "\n",
    "                            insert_query = f\"INSERT INTO {table_name} VALUES ({', '.join(['%s']*len(row))})\"   \n",
    "        \n",
    "                            print(f\"Insert query: \",insert_query,tuple(row))\n",
    "\n",
    "                            cursor.execute(insert_query,tuple(row))\n",
    "                                \n",
    "                        connection.commit()\n",
    "                            # logging.debug(f\"Data inserted into '{table_name}' table\")\n",
    "                            # print(f\"Data inserted into '{table_name}' table\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Define your SQL query\n",
    "            schema_query = f\"\"\" SELECT table_name, column_name\n",
    "                            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                            WHERE table_schema = '{database}';\"\"\"\n",
    "\n",
    "            # Execute the query\n",
    "            cursor.execute(schema_query)\n",
    "\n",
    "            # Fetch all rows\n",
    "            rows = cursor.fetchall()\n",
    "\n",
    "            # Display the fetched data using st.write\n",
    "            # with st.sidebar:\n",
    "            # st.subheader(\"Schema:\", schema)\n",
    "            \n",
    "            for row in rows:\n",
    "                table_name, column_name = row\n",
    "                if table_name not in schema:\n",
    "                    \n",
    "                    schema[table_name] = []\n",
    "                schema[table_name].append(column_name)\n",
    "            # st.write(\"Schema:\", schema)\n",
    "            # connection.commit()\n",
    "            print(\"Data successfully imported into the MySQL database.\")\n",
    "            #excel_accepted = True\n",
    "            return connection, schema\n",
    "        except Error as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        # finally:\n",
    "        #     if connection.is_connected():\n",
    "        #         cursor.close()\n",
    "        #         connection.close()\n",
    "        #         print(\"Connection closed.\")\n",
    "\n",
    "# Replace the placeholders with your MySQL details\n",
    "#excel_file_path = 'd:\\OFFICE\\AI\\DemandScience\\DummyData.xlsx'\n",
    "#database_name = 'sales_v1'\n",
    "  # Use 'localhost' if MySQL is on the same machine, otherwise provide the IP address\n",
    "\n",
    "#excel_to_mysql(excel_file_path, database_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13-digit number: 1705645170950\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "input_string = \"textbox_1705645170950\"\n",
    "\n",
    "# Use a regular expression to extract the 13-digit number\n",
    "match = re.search(r'\\d{13}', input_string)\n",
    "\n",
    "if match:\n",
    "    extracted_number = match.group(0)\n",
    "    print(\"Extracted 13-digit number:\", extracted_number)\n",
    "else:\n",
    "    print(\"No 13-digit number found in the input string.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "form_schema = []\n",
    "mongo_uri = \"mongodb+srv://lelafeprojs:jnU61BQJbxxQEEbA@cluster0.faiklh9.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(mongo_uri)\n",
    "db = client.db_stagingqforms\n",
    "forms = db.forms\n",
    "form_entries = db.form_entries\n",
    "controls = db.controls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data_object = {\\n    '_id': ObjectId('65aa19926524000064007752'),\\n    'form_id': '65aa1471172900009400700a',\\n    'textbox_1705645170950': 'andleeb fatima',\\n    'textbox_1705645182967': 'andleeb',\\n    'textbox_1705645196389': 'fatima',\\n    'textbox_1705645202787': 'naik',\\n    'paragraph_1705645209717': '<p>srinagar</p>',\\n    'singlechoice_1705645229756': [{'id': 1705645229811, 'value': 'employee', 'other': False}],\\n    'phone_1705645258571': '+91 78886 65567',\\n    'needApproval': False,\\n    '__qf__saveAndResumeLater': False,\\n    'restartWorkflow': False,\\n    'status': 'Submitted',\\n    'assignedEdit': False,\\n    'isPreviewEntry': False,\\n    'isReviewEntry': False,\\n    '__qf__token_saveAndResumeLater': '356b7cfd1d3a796c688ec4918d5a6ca9755482eb',\\n    'ip': '115.247.65.74',\\n    'submittedByName': 'Shah Asif',\\n    'submittedByEmail': 'shah.aasif1@gmail.com',\\n    'clientid': ObjectId('633564e54027000086001c05'),\\n    'guid': '',\\n    'created_at': datetime(2024, 1, 19, 6, 41, 22),\\n    'updated_at': datetime(2024, 1, 19, 6, 41, 22),\\n    'blob': ''\\n}\\n\\n# resulting_schema = create_schema(data_object)\\n# print(resulting_schema)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from bson import ObjectId\n",
    "\n",
    "def create_schema(data):\n",
    "    schema = {}\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, ObjectId):\n",
    "            # If the value is an ObjectId, assume it's the _id field\n",
    "            schema['_id'] = ObjectId\n",
    "        elif isinstance(value, str):\n",
    "            # If the value is a string, assume it's a string field\n",
    "            schema[key] = str\n",
    "        elif isinstance(value, int):\n",
    "            # If the value is an integer, check if it's a 13-digit number\n",
    "            if len(str(value)) == 13:\n",
    "                schema[key] = int  # Treat it as a 13-digit number\n",
    "            else:\n",
    "                schema[key] = str  # Treat it as a regular string\n",
    "        elif isinstance(value, bool):\n",
    "            # If the value is a boolean, assume it's a boolean field\n",
    "            schema[key] = bool\n",
    "        elif isinstance(value, list):\n",
    "            # If the value is a list, assume it's a list of dictionaries\n",
    "            if value and isinstance(value[0], dict):\n",
    "                # Recursive call to handle nested dictionaries in the list\n",
    "                schema[key] = [create_schema(value[0])]\n",
    "            else:\n",
    "                schema[key] = list\n",
    "        elif isinstance(value, datetime):\n",
    "            # If the value is a datetime, assume it's a datetime field\n",
    "            schema[key] = datetime\n",
    "        else:\n",
    "            # If the data type is not recognized, treat it as a string\n",
    "            schema[key] = str\n",
    "    return schema\n",
    "\n",
    "# Example usage:\n",
    "'''data_object = {\n",
    "    '_id': ObjectId('65aa19926524000064007752'),\n",
    "    'form_id': '65aa1471172900009400700a',\n",
    "    'textbox_1705645170950': 'andleeb fatima',\n",
    "    'textbox_1705645182967': 'andleeb',\n",
    "    'textbox_1705645196389': 'fatima',\n",
    "    'textbox_1705645202787': 'naik',\n",
    "    'paragraph_1705645209717': '<p>srinagar</p>',\n",
    "    'singlechoice_1705645229756': [{'id': 1705645229811, 'value': 'employee', 'other': False}],\n",
    "    'phone_1705645258571': '+91 78886 65567',\n",
    "    'needApproval': False,\n",
    "    '__qf__saveAndResumeLater': False,\n",
    "    'restartWorkflow': False,\n",
    "    'status': 'Submitted',\n",
    "    'assignedEdit': False,\n",
    "    'isPreviewEntry': False,\n",
    "    'isReviewEntry': False,\n",
    "    '__qf__token_saveAndResumeLater': '356b7cfd1d3a796c688ec4918d5a6ca9755482eb',\n",
    "    'ip': '115.247.65.74',\n",
    "    'submittedByName': 'Shah Asif',\n",
    "    'submittedByEmail': 'shah.aasif1@gmail.com',\n",
    "    'clientid': ObjectId('633564e54027000086001c05'),\n",
    "    'guid': '',\n",
    "    'created_at': datetime(2024, 1, 19, 6, 41, 22),\n",
    "    'updated_at': datetime(2024, 1, 19, 6, 41, 22),\n",
    "    'blob': ''\n",
    "}\n",
    "\n",
    "# resulting_schema = create_schema(data_object)\n",
    "# print(resulting_schema)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORM DATA: \n",
      " {'_id': ObjectId('65aa19926524000064007752'), 'form_id': '65aa1471172900009400700a', 'textbox_1705645170950': 'andleeb fatima', 'textbox_1705645182967': 'andleeb', 'textbox_1705645196389': 'fatima', 'textbox_1705645202787': 'naik', 'paragraph_1705645209717': '<p>srinagar</p>', 'singlechoice_1705645229756': [{'id': 1705645229811, 'value': 'employee', 'other': False}], 'phone_1705645258571': '+91 78886 65567', 'needApproval': False, '__qf__saveAndResumeLater': False, 'restartWorkflow': False, 'status': 'Submitted', 'assignedEdit': False, 'isPreviewEntry': False, 'isReviewEntry': False, '__qf__token_saveAndResumeLater': '356b7cfd1d3a796c688ec4918d5a6ca9755482eb', 'ip': '115.247.65.74', 'submittedByName': 'Shah Asif', 'submittedByEmail': 'shah.aasif1@gmail.com', 'clientid': ObjectId('633564e54027000086001c05'), 'guid': '', 'created_at': datetime.datetime(2024, 1, 19, 6, 41, 22), 'updated_at': datetime.datetime(2024, 1, 19, 6, 41, 22), 'blob': ''}\n",
      "{'_id': <class 'bson.objectid.ObjectId'>, 'form_id': <class 'str'>, 'textbox_1705645170950': <class 'str'>, 'textbox_1705645182967': <class 'str'>, 'textbox_1705645196389': <class 'str'>, 'textbox_1705645202787': <class 'str'>, 'paragraph_1705645209717': <class 'str'>, 'singlechoice_1705645229756': [{'id': <class 'int'>, 'value': <class 'str'>, 'other': <class 'str'>}], 'phone_1705645258571': <class 'str'>, 'needApproval': <class 'str'>, '__qf__saveAndResumeLater': <class 'str'>, 'restartWorkflow': <class 'str'>, 'status': <class 'str'>, 'assignedEdit': <class 'str'>, 'isPreviewEntry': <class 'str'>, 'isReviewEntry': <class 'str'>, '__qf__token_saveAndResumeLater': <class 'str'>, 'ip': <class 'str'>, 'submittedByName': <class 'str'>, 'submittedByEmail': <class 'str'>, 'guid': <class 'str'>, 'created_at': <class 'datetime.datetime'>, 'updated_at': <class 'datetime.datetime'>, 'blob': <class 'str'>}\n",
      "FORM DATA: \n",
      " {'_id': ObjectId('65aa1a5f465a000047000da2'), 'form_id': '65aa1471172900009400700a', 'textbox_1705645170950': 'junaid rafiq shah', 'textbox_1705645182967': 'junaid', 'textbox_1705645196389': 'rafiq', 'textbox_1705645202787': 'shah', 'paragraph_1705645209717': '<p>rajbagh srinagar </p>', 'singlechoice_1705645229756': [{'id': 1705645229811, 'value': 'employee', 'other': False}], 'phone_1705645258571': '+1 788-933-3333', 'needApproval': False, '__qf__saveAndResumeLater': False, 'restartWorkflow': False, 'status': 'Submitted', 'assignedEdit': False, 'isPreviewEntry': False, 'isReviewEntry': False, '__qf__token_saveAndResumeLater': '65844c4d41c280fe5b3ef51849d455d2129b160e', 'ip': '115.247.65.74', 'submittedByName': 'Shah Asif', 'submittedByEmail': 'shah.aasif1@gmail.com', 'clientid': ObjectId('633564e54027000086001c05'), 'guid': '', 'created_at': datetime.datetime(2024, 1, 19, 6, 44, 47), 'updated_at': datetime.datetime(2024, 1, 19, 6, 44, 47), 'blob': ''}\n",
      "{'_id': <class 'bson.objectid.ObjectId'>, 'form_id': <class 'str'>, 'textbox_1705645170950': <class 'str'>, 'textbox_1705645182967': <class 'str'>, 'textbox_1705645196389': <class 'str'>, 'textbox_1705645202787': <class 'str'>, 'paragraph_1705645209717': <class 'str'>, 'singlechoice_1705645229756': [{'id': <class 'int'>, 'value': <class 'str'>, 'other': <class 'str'>}], 'phone_1705645258571': <class 'str'>, 'needApproval': <class 'str'>, '__qf__saveAndResumeLater': <class 'str'>, 'restartWorkflow': <class 'str'>, 'status': <class 'str'>, 'assignedEdit': <class 'str'>, 'isPreviewEntry': <class 'str'>, 'isReviewEntry': <class 'str'>, '__qf__token_saveAndResumeLater': <class 'str'>, 'ip': <class 'str'>, 'submittedByName': <class 'str'>, 'submittedByEmail': <class 'str'>, 'guid': <class 'str'>, 'created_at': <class 'datetime.datetime'>, 'updated_at': <class 'datetime.datetime'>, 'blob': <class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "form_data_query= '{\"form_id\":\"65aa1471172900009400700a\"}'\n",
    "\n",
    "form_data_query = eval(form_data_query)\n",
    "form_data = db.form_entries.find(form_data_query)\n",
    "for record in form_data:\n",
    "    # print(f\"FORM DATA: \\n {record}\")\n",
    "\n",
    "    resulting_schema = create_schema(record)\n",
    "    print(resulting_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "SSL handshake failed: ac-f87oqda-shard-00-00.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007),SSL handshake failed: ac-f87oqda-shard-00-02.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007),SSL handshake failed: ac-f87oqda-shard-00-01.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007), Timeout: 30s, Topology Description: <TopologyDescription id: 65abe882b6a1da8b687c22a3, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-f87oqda-shard-00-00.faiklh9.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-f87oqda-shard-00-00.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')>, <ServerDescription ('ac-f87oqda-shard-00-01.faiklh9.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-f87oqda-shard-00-01.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')>, <ServerDescription ('ac-f87oqda-shard-00-02.faiklh9.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-f87oqda-shard-00-02.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m form_data_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(form_data_query)\n\u001b[0;32m     12\u001b[0m form_data \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mform_entries\u001b[38;5;241m.\u001b[39mfind(form_data_query)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m form_data:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# print(record)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     resulting_schema \u001b[38;5;241m=\u001b[39m create_schema(record)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(resulting_schema)\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\cursor.py:1248\u001b[0m, in \u001b[0;36mCursor.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__empty:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m-> 1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\cursor.py:1139\u001b[0m, in \u001b[0;36mCursor._refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__data)\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__session:\n\u001b[1;32m-> 1139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Query\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__min \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__max) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__hint:\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\mongo_client.py:1740\u001b[0m, in \u001b[0;36mMongoClient._ensure_session\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\n\u001b[0;32m   1737\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1738\u001b[0m     \u001b[38;5;66;03m# Don't make implicit sessions causally consistent. Applications\u001b[39;00m\n\u001b[0;32m   1739\u001b[0m     \u001b[38;5;66;03m# should always opt-in.\u001b[39;00m\n\u001b[1;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__start_session\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_consistency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ConfigurationError, InvalidOperation):\n\u001b[0;32m   1742\u001b[0m     \u001b[38;5;66;03m# Sessions not supported.\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\mongo_client.py:1685\u001b[0m, in \u001b[0;36mMongoClient.__start_session\u001b[1;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__start_session\u001b[39m(\u001b[38;5;28mself\u001b[39m, implicit, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1683\u001b[0m     \u001b[38;5;66;03m# Raises ConfigurationError if sessions are not supported.\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m implicit:\n\u001b[1;32m-> 1685\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_topology\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_implicit_session_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m         server_session \u001b[38;5;241m=\u001b[39m _EmptyServerSession()\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\topology.py:538\u001b[0m, in \u001b[0;36mTopology._check_implicit_session_support\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_implicit_session_support\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 538\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_session_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\topology.py:554\u001b[0m, in \u001b[0;36mTopology._check_session_support\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_servers_loop(\n\u001b[0;32m    551\u001b[0m             any_server_selector, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_server_selection_timeout(), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    552\u001b[0m         )\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description\u001b[38;5;241m.\u001b[39mreadable_servers:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_servers_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreadable_server_selector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_server_selection_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m session_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_description\u001b[38;5;241m.\u001b[39mlogical_session_timeout_minutes\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Junaid Rafiq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymongo\\topology.py:238\u001b[0m, in \u001b[0;36mTopology._select_servers_loop\u001b[1;34m(self, selector, timeout, address)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m server_descriptions:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# No suitable servers.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m now \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m--> 238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ServerSelectionTimeoutError(\n\u001b[0;32m    239\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, Timeout: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124ms, Topology Description: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message(selector), timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription)\n\u001b[0;32m    241\u001b[0m         )\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_opened()\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_check_all()\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: SSL handshake failed: ac-f87oqda-shard-00-00.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007),SSL handshake failed: ac-f87oqda-shard-00-02.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007),SSL handshake failed: ac-f87oqda-shard-00-01.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007), Timeout: 30s, Topology Description: <TopologyDescription id: 65abe882b6a1da8b687c22a3, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-f87oqda-shard-00-00.faiklh9.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-f87oqda-shard-00-00.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')>, <ServerDescription ('ac-f87oqda-shard-00-01.faiklh9.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-f87oqda-shard-00-01.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')>, <ServerDescription ('ac-f87oqda-shard-00-02.faiklh9.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-f87oqda-shard-00-02.faiklh9.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')>]>"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Dictionary to store mapping\n",
    "mapping_dict = {}\n",
    "\n",
    "# Regular expression to match 13-digit numbers in keys\n",
    "pattern = re.compile(r'\\d{13}')\n",
    "# Assuming 'schema' is the inferred schema from the previous code\n",
    "# {id:1705645170950}\t\n",
    "form_data_query = '{\"form_id\":\"65aa1471172900009400700a\"}'\n",
    "form_data_query = eval(form_data_query)\n",
    "form_data = db.form_entries.find(form_data_query)\n",
    "for record in form_data:\n",
    "    # print(record)\n",
    "    \n",
    "    resulting_schema = create_schema(record)\n",
    "    print(resulting_schema)\n",
    "    \n",
    "    for key, value in resulting_schema.items():\n",
    "        # print(key)\n",
    "        # Check if key contains a 13-digit number\n",
    "        match = re.search(pattern, key)\n",
    "        if match:\n",
    "            print('matched re: ',match)\n",
    "            extracted_number = match.group(0)\n",
    "            \n",
    "            # Query control collection to get fieldname value\n",
    "            # control_data = db.control.find_one(f'{\"id\": \"{extracted_number}\"}')\n",
    "            print(extracted_number)\n",
    "            extracted_number = eval(extracted_number)\n",
    "            control_data = db.control.find_one({\"id\": extracted_number})\n",
    "            # control_data = db.control.find_one({\"id\": ObjectId(extracted_number)})\n",
    "\n",
    "\n",
    "            # Check if control_data and fieldname exist\n",
    "            if control_data and 'fieldName' in control_data:\n",
    "                fieldname_value = control_data['fieldName']\n",
    "                \n",
    "                # Map the key name of schema with the value of fieldname value\n",
    "                mapping_dict[key] = fieldname_value\n",
    "    \n",
    "    \n",
    "print(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data = db.control.find_one({\"id\": \"1705645170950\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EmployeeID', 'Last_Name', 'age', 'BirthDate', 'Photo', 'FirstName']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from keyword import iskeyword\n",
    "\n",
    "def clean_column_name(col):\n",
    "    # Remove leading and trailing spaces\n",
    "    cleaned_col = col.strip()\n",
    "    \n",
    "    # Replace spaces with underscores\n",
    "    cleaned_col = cleaned_col.replace(\" \", \"_\")\n",
    "    \n",
    "    # Replace special characters with underscores\n",
    "    cleaned_col = re.sub(r'[^a-zA-Z0-9_]', '', cleaned_col)\n",
    "    \n",
    "    # Check if the cleaned column name is an SQL keyword\n",
    "    if iskeyword(cleaned_col.upper()):\n",
    "        cleaned_col = f\"{cleaned_col}_\"\n",
    "    \n",
    "    return cleaned_col\n",
    "\n",
    "column_types={'EmployeeID', 'Last Name#', 'FirstName', 'BirthDate%', 'Photo','age'}\n",
    "# Apply the cleaning function to column names\n",
    "cleaned_column_names = [clean_column_name(col) for col in list(column_types)]\n",
    "print(cleaned_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-25: Match\n",
      "25-01-2022: Match\n",
      "2022-01-25 15:30:451: No match\n",
      "2022-01-25 15:30:45: Match\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "datetime_formats_pattern = re.compile(\n",
    "    r'^(\\d{4}-\\d{2}-\\d{2}(\\s+\\d{2}:\\d{2}:\\d{2})?|\\d{2}-\\d{2}-\\d{4}(\\s+\\d{2}:\\d{2}:\\d{2})?)$'\n",
    ")\n",
    "\n",
    "# Test examples\n",
    "examples = [\n",
    "    '2022-01-25',\n",
    "    '25-01-2022',\n",
    "    '2022-01-25 15:30:45',\n",
    "    '2022-01-25 15:30:45',\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    match = datetime_formats_pattern.match(example)\n",
    "    print(f'{example}: {\"Match\" if match else \"No match\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'column1' data type: NUMERIC\n",
      "Column 'column2' data type: NUMERIC\n",
      "Column 'column3' data type: NUMERIC\n",
      "Column 'column4' data type: TEXT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def infer_data_type(series):\n",
    "    # Infer the data type of the column based on the first non-null value\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        data_type = 'NUMERIC'   \n",
    "    elif pd.api.types.is_float_dtype(series):\n",
    "        data_type = 'FLOAT'\n",
    "    elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "        data_type = 'DATETIME'\n",
    "    elif pd.api.types.is_string_dtype(series):\n",
    "        print('stringgg')\n",
    "        # Check for string (TEXT or VARCHAR based on length)\n",
    "        # max_length = series.str.len().max()\n",
    "        # data_type = f\"VARCHAR({min(max_length, 255)})\"\n",
    "        \n",
    "        # Check if the data contains a pattern resembling a dollar sign and numeric values\n",
    "        if series.str.contains(r'\\$\\s*\\d+', na=False).any():\n",
    "            data_type = 'NUMERIC'\n",
    "        else:\n",
    "            data_type = 'TEXT'\n",
    "\n",
    "    elif pd.api.types.is_bool_dtype(series):\n",
    "        data_type = 'BOOLEAN'   \n",
    "    else:\n",
    "        # Default to TEXT if the data type is not recognized\n",
    "        data_type = 'TEXT'\n",
    "        \n",
    "    print(f\"Column data type: {data_type}\")\n",
    "    return data_type\n",
    "\n",
    "# Example usage:\n",
    "data = {\n",
    "    'column1': [1, 2, 3],\n",
    "    'column2': ['2022-01-29', '$1', '2022-01-31'],\n",
    "    'column3': ['text1', '$50', 'text3'],\n",
    "    'column4': [True, False, True],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for column in df.columns:\n",
    "    data_type = infer_data_type(df[column])\n",
    "    print(f\"Column '{column}' data type: {data_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'pricing' data type: NUMERIC\n",
      "Values matching the regular expression:\n",
      "0     $11\n",
      "1     $12\n",
      "2     $13\n",
      "3     $14\n",
      "4     $15\n",
      "5     $16\n",
      "6     $17\n",
      "7     $18\n",
      "8     $78\n",
      "9     $20\n",
      "10    $21\n",
      "11    $22\n",
      "12    $23\n",
      "13    $24\n",
      "14    $25\n",
      "15    $26\n",
      "16    $27\n",
      "17    $28\n",
      "18    $29\n",
      "19    $30\n",
      "Name: pricing, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'pricing': ['$11', '$12', '$13', '$14', '$15', '$16', '$17', '$18', '$78', '$20', '$21', '$22', '$23', '$24', '$25', '$26', '$27', '$28', '$29', '$30']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to infer data type\n",
    "def infer_data_type(series):\n",
    "    if series.str.contains(r'\\$\\s*\\d+', na=False).any():\n",
    "        return 'NUMERIC'\n",
    "    else:\n",
    "        return 'TEXT'\n",
    "\n",
    "# Apply the function to the 'pricing' column\n",
    "data_type = infer_data_type(df['pricing'])\n",
    "\n",
    "# Print the inferred data type\n",
    "print(f\"Column 'pricing' data type: {data_type}\")\n",
    "\n",
    "# Print values matching the regular expression\n",
    "matching_values = df['pricing'][df['pricing'].str.contains(r'\\$\\s*\\d+', na=False)]\n",
    "print(\"Values matching the regular expression:\")\n",
    "print(matching_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def validate_dbname_naming_convention(name):\n",
    "    # Ensure the name starts with a letter (MySQL requirement)\n",
    "    if not name or not name[0].isalpha():\n",
    "        return False\n",
    "\n",
    "    # Check if the name contains only letters, numbers, and underscores\n",
    "    return bool(re.match(r'^[a-zA-Z0-9_]*$', name))\n",
    "\n",
    "# Example usage:\n",
    "name1 = \"ValidName-123\"\n",
    "name2 = \"Invalid Name\"\n",
    "name3 = \"123InvalidName\"\n",
    "\n",
    "print(is_valid_mysql_db_name(name1))  # Output: True\n",
    "print(is_valid_mysql_db_name(name2))  # Output: False\n",
    "print(is_valid_mysql_db_name(name3))  # Output: False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
